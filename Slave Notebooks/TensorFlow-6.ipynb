{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7500 images belonging to 10 classes.\n",
      "Found 2500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "train_datagen = ImageDataGenerator() #no rescaling required as pre-trained model is already rescaling it\n",
    "test_datagen = ImageDataGenerator()  #if we rescale again, we'll get bad accuracy\n",
    "\n",
    "\n",
    "train_data = train_datagen.flow_from_directory('10_food_classes_all_data/train/',\n",
    "                                   batch_size = 32,\n",
    "                                  target_size=(128, 128),\n",
    "                                   class_mode='categorical',\n",
    "                                   shuffle = True, #shuffle is required because data is highly ordered into respective classes\n",
    "                                   seed=42)\n",
    "test_data = test_datagen.flow_from_directory('10_food_classes_all_data/test/',\n",
    "                                  batch_size=32,\n",
    "                                  target_size=(128, 128),\n",
    "                                  class_mode='categorical',\n",
    "                                  shuffle = True,\n",
    "                                  seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape = (128, 128, 3))\n",
    "\n",
    "#for Functional API, input layer and hidden layers should be separate otherwise hidden layers won't be able to take tensors\n",
    "\n",
    "x = tf.keras.layers.Conv2D(64, kernel_size = 3)(inputs)\n",
    "#like composition of functions, this style is called functional way of passing layers (Functional API)\n",
    "x = tf.keras.layers.MaxPool2D(2)(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation = 'softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs, outputs) #inputs and outputs functions from outside need to be connected (like a circle)\n",
    "\n",
    "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    "              metrics = ['accuracy'] \n",
    "              )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 126, 126, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 63, 63, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 254016)            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                2540170   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2541962 (9.70 MB)\n",
      "Trainable params: 2541962 (9.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/235 [==============================] - 20s 85ms/step - loss: 596.3521 - accuracy: 0.1920\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 20s 83ms/step - loss: 78.3258 - accuracy: 0.4653\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 20s 86ms/step - loss: 39.7295 - accuracy: 0.6583\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 20s 84ms/step - loss: 18.6969 - accuracy: 0.7901\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 21s 87ms/step - loss: 15.8473 - accuracy: 0.8256\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 6s 80ms/step - loss: 174.5893 - accuracy: 0.2224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[174.5893096923828, 0.2223999947309494]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data) #very bad accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB0(include_top = False) #pre-trained model with hundreds of layers\n",
    "#include_top = False doesn't import the input layer of the model as we are giving our model to it\n",
    "base_model.trainable = False #we are not training base model with our inputs !!!\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape = (128, 128, 3))\n",
    "x = base_model(inputs) #directly pass it through base model\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "#x = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation = 'softmax')(x)\n",
    "model = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    "              metrics = ['accuracy'] \n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb0 (Functional  (None, None, None, 1280   4049571   \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " global_average_pooling2d_4  (None, 1280)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                12810     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4062381 (15.50 MB)\n",
      "Trainable params: 12810 (50.04 KB)\n",
      "Non-trainable params: 4049571 (15.45 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() #we have more parameters here in pre-trained model compared to previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/235 [==============================] - 33s 128ms/step - loss: 1.0185 - accuracy: 0.6903 - val_loss: 0.5410 - val_accuracy: 0.8292\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 29s 123ms/step - loss: 0.6424 - accuracy: 0.7988 - val_loss: 0.5177 - val_accuracy: 0.8417\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 29s 125ms/step - loss: 0.5662 - accuracy: 0.8212 - val_loss: 0.4098 - val_accuracy: 0.8729\n",
      "Epoch 4/5\n",
      " 21/235 [=>............................] - ETA: 24s - loss: 0.5320 - accuracy: 0.8318"
     ]
    }
   ],
   "source": [
    "model.fit(train_data, epochs = 5,\n",
    "           validation_data = test_data,\n",
    "           steps_per_epoch = len(train_data), #no. of steps taken on validation curve\n",
    "           validation_steps = int(0.2 * len(test_data))) \n",
    "#only 20% of test data is chosen to learn => slowly and accurately learns it\n",
    "\n",
    "#very bad accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 10s 130ms/step - loss: 0.4273 - accuracy: 0.8624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4272502362728119, 0.8623999953269958]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data) #good accuracy, all due to pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.src.engine.input_layer.InputLayer at 0x2e1f37410>,\n",
       " <keras.src.layers.preprocessing.image_preprocessing.Rescaling at 0x2e1f0b650>,\n",
       " <keras.src.layers.preprocessing.normalization.Normalization at 0x2e1cd6090>,\n",
       " <keras.src.layers.preprocessing.image_preprocessing.Rescaling at 0x2e1f05910>,\n",
       " <keras.src.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x2e1ef9690>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2e1edde50>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2e1f04f90>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2caf527d0>,\n",
       " <keras.src.layers.convolutional.depthwise_conv2d.DepthwiseConv2D at 0x2caf65450>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2caf72710>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2db3a7710>,\n",
       " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x2caf8b850>,\n",
       " <keras.src.layers.reshaping.reshape.Reshape at 0x2caf70890>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2e2073590>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2e20752d0>,\n",
       " <keras.src.layers.merging.multiply.Multiply at 0x2e2077bd0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2e1f460d0>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2e2076610>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2e2083890>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2caf8ae10>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2caf9d810>,\n",
       " <keras.src.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x28fe63c50>,\n",
       " <keras.src.layers.convolutional.depthwise_conv2d.DepthwiseConv2D at 0x2e208f810>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2e208fe50>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2e2054050>,\n",
       " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x2e208fd90>,\n",
       " <keras.src.layers.reshaping.reshape.Reshape at 0x2caf8bc10>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2e20a7d90>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2ccbb9390>,\n",
       " <keras.src.layers.merging.multiply.Multiply at 0x2caf8bbd0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb1089d0>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x17fbf1510>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2e1f103d0>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb108e50>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2e20a5cd0>,\n",
       " <keras.src.layers.convolutional.depthwise_conv2d.DepthwiseConv2D at 0x2cb110790>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb11fad0>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2caf628d0>,\n",
       " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x2cb12bf10>,\n",
       " <keras.src.layers.reshaping.reshape.Reshape at 0x2cb137ad0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb135610>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2e1bbc710>,\n",
       " <keras.src.layers.merging.multiply.Multiply at 0x2e20476d0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2e1ceaa10>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2caf9ff90>,\n",
       " <keras.src.layers.regularization.dropout.Dropout at 0x2caf70950>,\n",
       " <keras.src.layers.merging.add.Add at 0x2cb11cd50>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2db3e2190>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb14ca90>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2e1f10190>,\n",
       " <keras.src.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x2da7617d0>,\n",
       " <keras.src.layers.convolutional.depthwise_conv2d.DepthwiseConv2D at 0x2e2072c90>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb11d1d0>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2cb16a9d0>,\n",
       " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x2e1c81a10>,\n",
       " <keras.src.layers.reshaping.reshape.Reshape at 0x2cb16a610>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb177fd0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb174ed0>,\n",
       " <keras.src.layers.merging.multiply.Multiply at 0x2cb1762d0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb144c10>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb161350>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb177dd0>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb12a2d0>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2caf436d0>,\n",
       " <keras.src.layers.convolutional.depthwise_conv2d.DepthwiseConv2D at 0x2cb140d50>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb14fe10>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2e2070410>,\n",
       " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x2cb145c10>,\n",
       " <keras.src.layers.reshaping.reshape.Reshape at 0x2cb177e50>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb197810>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb195250>,\n",
       " <keras.src.layers.merging.multiply.Multiply at 0x2cb1080d0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb19e010>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb19fb90>,\n",
       " <keras.src.layers.regularization.dropout.Dropout at 0x2e2083150>,\n",
       " <keras.src.layers.merging.add.Add at 0x2e1f0a990>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb1afa10>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb136190>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2cb174290>,\n",
       " <keras.src.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x2e1efa090>,\n",
       " <keras.src.layers.convolutional.depthwise_conv2d.DepthwiseConv2D at 0x2cb1bbc90>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb1af310>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2cb1a32d0>,\n",
       " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x2cb1bd450>,\n",
       " <keras.src.layers.reshaping.reshape.Reshape at 0x2cb161dd0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x17cfc8710>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb1b8450>,\n",
       " <keras.src.layers.merging.multiply.Multiply at 0x2cb1acc50>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb169190>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb1d3250>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb1ddd10>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb1a3ed0>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2cb1d0750>,\n",
       " <keras.src.layers.convolutional.depthwise_conv2d.DepthwiseConv2D at 0x2cb1b8cd0>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb1b8490>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2cb1f0690>,\n",
       " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x2cb1fe4d0>,\n",
       " <keras.src.layers.reshaping.reshape.Reshape at 0x2cb1ffc90>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb1fe990>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb1dda50>,\n",
       " <keras.src.layers.merging.multiply.Multiply at 0x2cb1fc5d0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb1bb090>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb1ea210>,\n",
       " <keras.src.layers.regularization.dropout.Dropout at 0x2cb19db50>,\n",
       " <keras.src.layers.merging.add.Add at 0x2cb1dcf50>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb1adf10>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb1bea10>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2cb205710>,\n",
       " <keras.src.layers.convolutional.depthwise_conv2d.DepthwiseConv2D at 0x2cb14c390>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb2058d0>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2cb2065d0>,\n",
       " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x2cb212b50>,\n",
       " <keras.src.layers.reshaping.reshape.Reshape at 0x2cb216cd0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb227050>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb1a1750>,\n",
       " <keras.src.layers.merging.multiply.Multiply at 0x2e1f10dd0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb229010>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb1d1a50>,\n",
       " <keras.src.layers.regularization.dropout.Dropout at 0x2cb19d210>,\n",
       " <keras.src.layers.merging.add.Add at 0x2cb237710>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb242990>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2e204dfd0>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2cb1bda10>,\n",
       " <keras.src.layers.convolutional.depthwise_conv2d.DepthwiseConv2D at 0x2cb24a850>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb1aee10>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2cb24bd50>,\n",
       " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x2cb229790>,\n",
       " <keras.src.layers.reshaping.reshape.Reshape at 0x2cb25b910>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb266650>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb267750>,\n",
       " <keras.src.layers.merging.multiply.Multiply at 0x2cb266ed0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb273b90>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb2714d0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb277650>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb237810>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2cb276c90>,\n",
       " <keras.src.layers.convolutional.depthwise_conv2d.DepthwiseConv2D at 0x2cb27ec10>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb287010>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2cb287dd0>,\n",
       " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x2cb285d10>,\n",
       " <keras.src.layers.reshaping.reshape.Reshape at 0x2cb2492d0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb274f90>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb236c50>,\n",
       " <keras.src.layers.merging.multiply.Multiply at 0x2cb242710>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2caf71150>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb1fe5d0>,\n",
       " <keras.src.layers.regularization.dropout.Dropout at 0x2cb1bc550>,\n",
       " <keras.src.layers.merging.add.Add at 0x2e1edd390>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb1b8d50>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2e2056cd0>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2cb234a10>,\n",
       " <keras.src.layers.convolutional.depthwise_conv2d.DepthwiseConv2D at 0x2cb2a1e50>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb2a2590>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2cb2a0210>,\n",
       " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x2cb2a9650>,\n",
       " <keras.src.layers.reshaping.reshape.Reshape at 0x2cb2aad90>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb2aa910>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb2b7610>,\n",
       " <keras.src.layers.merging.multiply.Multiply at 0x2cb2a08d0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb2b4450>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb2bff10>,\n",
       " <keras.src.layers.regularization.dropout.Dropout at 0x2cb2c80d0>,\n",
       " <keras.src.layers.merging.add.Add at 0x2cb2ca410>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb2c9dd0>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb110610>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2cb2d3f90>,\n",
       " <keras.src.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x2cb2cb650>,\n",
       " <keras.src.layers.convolutional.depthwise_conv2d.DepthwiseConv2D at 0x2cb2dbe90>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb1f14d0>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2cb259550>,\n",
       " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x2cb2c8b50>,\n",
       " <keras.src.layers.reshaping.reshape.Reshape at 0x2cb2ee3d0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb2eed50>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb2f2710>,\n",
       " <keras.src.layers.merging.multiply.Multiply at 0x2cb2eeb90>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb2f3f90>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb1f2250>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb259590>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2de113d90>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2de110910>,\n",
       " <keras.src.layers.convolutional.depthwise_conv2d.DepthwiseConv2D at 0x2cb2ec4d0>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb2fde90>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2cb2f14d0>,\n",
       " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x2cb2f1710>,\n",
       " <keras.src.layers.reshaping.reshape.Reshape at 0x2cb2be810>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2de1121d0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb265ed0>,\n",
       " <keras.src.layers.merging.multiply.Multiply at 0x2cb1b84d0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb2d3810>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2de11d590>,\n",
       " <keras.src.layers.regularization.dropout.Dropout at 0x2cb2116d0>,\n",
       " <keras.src.layers.merging.add.Add at 0x2de12dd10>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2caf51f90>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb194f90>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2cb2734d0>,\n",
       " <keras.src.layers.convolutional.depthwise_conv2d.DepthwiseConv2D at 0x2de135d10>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2de134f90>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2de1364d0>,\n",
       " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x2cb229c90>,\n",
       " <keras.src.layers.reshaping.reshape.Reshape at 0x2de11f610>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2de144490>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2de14add0>,\n",
       " <keras.src.layers.merging.multiply.Multiply at 0x2de12d910>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2de153790>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2de153a90>,\n",
       " <keras.src.layers.regularization.dropout.Dropout at 0x2de15db10>,\n",
       " <keras.src.layers.merging.add.Add at 0x2de1351d0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2de15e650>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2cb2fed50>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2de164610>,\n",
       " <keras.src.layers.convolutional.depthwise_conv2d.DepthwiseConv2D at 0x2de16ead0>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2de16fcd0>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2de167210>,\n",
       " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x2de183850>,\n",
       " <keras.src.layers.reshaping.reshape.Reshape at 0x2de130050>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2de18bad0>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2de164f50>,\n",
       " <keras.src.layers.merging.multiply.Multiply at 0x2de130f50>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2cb1a35d0>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2de18d350>,\n",
       " <keras.src.layers.regularization.dropout.Dropout at 0x2de18c3d0>,\n",
       " <keras.src.layers.merging.add.Add at 0x2de194510>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2de166f50>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2de16fad0>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2de164190>,\n",
       " <keras.src.layers.convolutional.depthwise_conv2d.DepthwiseConv2D at 0x2de151290>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2de12c4d0>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2de12fed0>,\n",
       " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x2cb2dadd0>,\n",
       " <keras.src.layers.reshaping.reshape.Reshape at 0x2de1a2790>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2de151d50>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2de1952d0>,\n",
       " <keras.src.layers.merging.multiply.Multiply at 0x2de1a3390>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2de1b6f10>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2de130090>,\n",
       " <keras.src.layers.convolutional.conv2d.Conv2D at 0x2de1b54d0>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x2de1b7a50>,\n",
       " <keras.src.layers.core.activation.Activation at 0x2de147790>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.layers #shows base model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_6 True\n",
      "1 efficientnetb0 False\n",
      "2 global_average_pooling2d_1 True\n",
      "3 dense_3 True\n"
     ]
    }
   ],
   "source": [
    "for num, layer in enumerate(model.layers):\n",
    "    print(num, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_5 False\n",
      "1 rescaling_2 False\n",
      "2 normalization_1 False\n",
      "3 rescaling_3 False\n",
      "4 stem_conv_pad False\n",
      "5 stem_conv False\n",
      "6 stem_bn False\n",
      "7 stem_activation False\n",
      "8 block1a_dwconv False\n",
      "9 block1a_bn False\n",
      "10 block1a_activation False\n",
      "11 block1a_se_squeeze False\n",
      "12 block1a_se_reshape False\n",
      "13 block1a_se_reduce False\n",
      "14 block1a_se_expand False\n",
      "15 block1a_se_excite False\n",
      "16 block1a_project_conv False\n",
      "17 block1a_project_bn False\n",
      "18 block2a_expand_conv False\n",
      "19 block2a_expand_bn False\n",
      "20 block2a_expand_activation False\n",
      "21 block2a_dwconv_pad False\n",
      "22 block2a_dwconv False\n",
      "23 block2a_bn False\n",
      "24 block2a_activation False\n",
      "25 block2a_se_squeeze False\n",
      "26 block2a_se_reshape False\n",
      "27 block2a_se_reduce False\n",
      "28 block2a_se_expand False\n",
      "29 block2a_se_excite False\n",
      "30 block2a_project_conv False\n",
      "31 block2a_project_bn False\n",
      "32 block2b_expand_conv False\n",
      "33 block2b_expand_bn False\n",
      "34 block2b_expand_activation False\n",
      "35 block2b_dwconv False\n",
      "36 block2b_bn False\n",
      "37 block2b_activation False\n",
      "38 block2b_se_squeeze False\n",
      "39 block2b_se_reshape False\n",
      "40 block2b_se_reduce False\n",
      "41 block2b_se_expand False\n",
      "42 block2b_se_excite False\n",
      "43 block2b_project_conv False\n",
      "44 block2b_project_bn False\n",
      "45 block2b_drop False\n",
      "46 block2b_add False\n",
      "47 block3a_expand_conv False\n",
      "48 block3a_expand_bn False\n",
      "49 block3a_expand_activation False\n",
      "50 block3a_dwconv_pad False\n",
      "51 block3a_dwconv False\n",
      "52 block3a_bn False\n",
      "53 block3a_activation False\n",
      "54 block3a_se_squeeze False\n",
      "55 block3a_se_reshape False\n",
      "56 block3a_se_reduce False\n",
      "57 block3a_se_expand False\n",
      "58 block3a_se_excite False\n",
      "59 block3a_project_conv False\n",
      "60 block3a_project_bn False\n",
      "61 block3b_expand_conv False\n",
      "62 block3b_expand_bn False\n",
      "63 block3b_expand_activation False\n",
      "64 block3b_dwconv False\n",
      "65 block3b_bn False\n",
      "66 block3b_activation False\n",
      "67 block3b_se_squeeze False\n",
      "68 block3b_se_reshape False\n",
      "69 block3b_se_reduce False\n",
      "70 block3b_se_expand False\n",
      "71 block3b_se_excite False\n",
      "72 block3b_project_conv False\n",
      "73 block3b_project_bn False\n",
      "74 block3b_drop False\n",
      "75 block3b_add False\n",
      "76 block4a_expand_conv False\n",
      "77 block4a_expand_bn False\n",
      "78 block4a_expand_activation False\n",
      "79 block4a_dwconv_pad False\n",
      "80 block4a_dwconv False\n",
      "81 block4a_bn False\n",
      "82 block4a_activation False\n",
      "83 block4a_se_squeeze False\n",
      "84 block4a_se_reshape False\n",
      "85 block4a_se_reduce False\n",
      "86 block4a_se_expand False\n",
      "87 block4a_se_excite False\n",
      "88 block4a_project_conv False\n",
      "89 block4a_project_bn False\n",
      "90 block4b_expand_conv False\n",
      "91 block4b_expand_bn False\n",
      "92 block4b_expand_activation False\n",
      "93 block4b_dwconv False\n",
      "94 block4b_bn False\n",
      "95 block4b_activation False\n",
      "96 block4b_se_squeeze False\n",
      "97 block4b_se_reshape False\n",
      "98 block4b_se_reduce False\n",
      "99 block4b_se_expand False\n",
      "100 block4b_se_excite False\n",
      "101 block4b_project_conv False\n",
      "102 block4b_project_bn False\n",
      "103 block4b_drop False\n",
      "104 block4b_add False\n",
      "105 block4c_expand_conv False\n",
      "106 block4c_expand_bn False\n",
      "107 block4c_expand_activation False\n",
      "108 block4c_dwconv False\n",
      "109 block4c_bn False\n",
      "110 block4c_activation False\n",
      "111 block4c_se_squeeze False\n",
      "112 block4c_se_reshape False\n",
      "113 block4c_se_reduce False\n",
      "114 block4c_se_expand False\n",
      "115 block4c_se_excite False\n",
      "116 block4c_project_conv False\n",
      "117 block4c_project_bn False\n",
      "118 block4c_drop False\n",
      "119 block4c_add False\n",
      "120 block5a_expand_conv False\n",
      "121 block5a_expand_bn False\n",
      "122 block5a_expand_activation False\n",
      "123 block5a_dwconv False\n",
      "124 block5a_bn False\n",
      "125 block5a_activation False\n",
      "126 block5a_se_squeeze False\n",
      "127 block5a_se_reshape False\n",
      "128 block5a_se_reduce False\n",
      "129 block5a_se_expand False\n",
      "130 block5a_se_excite False\n",
      "131 block5a_project_conv False\n",
      "132 block5a_project_bn False\n",
      "133 block5b_expand_conv False\n",
      "134 block5b_expand_bn False\n",
      "135 block5b_expand_activation False\n",
      "136 block5b_dwconv False\n",
      "137 block5b_bn False\n",
      "138 block5b_activation False\n",
      "139 block5b_se_squeeze False\n",
      "140 block5b_se_reshape False\n",
      "141 block5b_se_reduce False\n",
      "142 block5b_se_expand False\n",
      "143 block5b_se_excite False\n",
      "144 block5b_project_conv False\n",
      "145 block5b_project_bn False\n",
      "146 block5b_drop False\n",
      "147 block5b_add False\n",
      "148 block5c_expand_conv False\n",
      "149 block5c_expand_bn False\n",
      "150 block5c_expand_activation False\n",
      "151 block5c_dwconv False\n",
      "152 block5c_bn False\n",
      "153 block5c_activation False\n",
      "154 block5c_se_squeeze False\n",
      "155 block5c_se_reshape False\n",
      "156 block5c_se_reduce False\n",
      "157 block5c_se_expand False\n",
      "158 block5c_se_excite False\n",
      "159 block5c_project_conv False\n",
      "160 block5c_project_bn False\n",
      "161 block5c_drop False\n",
      "162 block5c_add False\n",
      "163 block6a_expand_conv False\n",
      "164 block6a_expand_bn False\n",
      "165 block6a_expand_activation False\n",
      "166 block6a_dwconv_pad False\n",
      "167 block6a_dwconv False\n",
      "168 block6a_bn False\n",
      "169 block6a_activation False\n",
      "170 block6a_se_squeeze False\n",
      "171 block6a_se_reshape False\n",
      "172 block6a_se_reduce False\n",
      "173 block6a_se_expand False\n",
      "174 block6a_se_excite False\n",
      "175 block6a_project_conv False\n",
      "176 block6a_project_bn False\n",
      "177 block6b_expand_conv False\n",
      "178 block6b_expand_bn False\n",
      "179 block6b_expand_activation False\n",
      "180 block6b_dwconv False\n",
      "181 block6b_bn False\n",
      "182 block6b_activation False\n",
      "183 block6b_se_squeeze False\n",
      "184 block6b_se_reshape False\n",
      "185 block6b_se_reduce False\n",
      "186 block6b_se_expand False\n",
      "187 block6b_se_excite False\n",
      "188 block6b_project_conv False\n",
      "189 block6b_project_bn False\n",
      "190 block6b_drop False\n",
      "191 block6b_add False\n",
      "192 block6c_expand_conv False\n",
      "193 block6c_expand_bn False\n",
      "194 block6c_expand_activation False\n",
      "195 block6c_dwconv False\n",
      "196 block6c_bn False\n",
      "197 block6c_activation False\n",
      "198 block6c_se_squeeze False\n",
      "199 block6c_se_reshape False\n",
      "200 block6c_se_reduce False\n",
      "201 block6c_se_expand False\n",
      "202 block6c_se_excite False\n",
      "203 block6c_project_conv False\n",
      "204 block6c_project_bn False\n",
      "205 block6c_drop False\n",
      "206 block6c_add False\n",
      "207 block6d_expand_conv False\n",
      "208 block6d_expand_bn False\n",
      "209 block6d_expand_activation False\n",
      "210 block6d_dwconv False\n",
      "211 block6d_bn False\n",
      "212 block6d_activation False\n",
      "213 block6d_se_squeeze False\n",
      "214 block6d_se_reshape False\n",
      "215 block6d_se_reduce False\n",
      "216 block6d_se_expand False\n",
      "217 block6d_se_excite False\n",
      "218 block6d_project_conv False\n",
      "219 block6d_project_bn False\n",
      "220 block6d_drop False\n",
      "221 block6d_add False\n",
      "222 block7a_expand_conv False\n",
      "223 block7a_expand_bn False\n",
      "224 block7a_expand_activation False\n",
      "225 block7a_dwconv False\n",
      "226 block7a_bn False\n",
      "227 block7a_activation False\n",
      "228 block7a_se_squeeze False\n",
      "229 block7a_se_reshape False\n",
      "230 block7a_se_reduce False\n",
      "231 block7a_se_expand False\n",
      "232 block7a_se_excite False\n",
      "233 block7a_project_conv False\n",
      "234 block7a_project_bn False\n",
      "235 top_conv False\n",
      "236 top_bn False\n",
      "237 top_activation False\n"
     ]
    }
   ],
   "source": [
    "for num, layer in enumerate(base_model.layers):\n",
    "    print(num, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"efficientnetb0\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, None, None, 3)]      0         []                            \n",
      "                                                                                                  \n",
      " rescaling_2 (Rescaling)     (None, None, None, 3)        0         ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " normalization_1 (Normaliza  (None, None, None, 3)        7         ['rescaling_2[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " rescaling_3 (Rescaling)     (None, None, None, 3)        0         ['normalization_1[0][0]']     \n",
      "                                                                                                  \n",
      " stem_conv_pad (ZeroPadding  (None, None, None, 3)        0         ['rescaling_3[0][0]']         \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stem_conv (Conv2D)          (None, None, None, 32)       864       ['stem_conv_pad[0][0]']       \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalizatio  (None, None, None, 32)       128       ['stem_conv[0][0]']           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stem_activation (Activatio  (None, None, None, 32)       0         ['stem_bn[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block1a_dwconv (DepthwiseC  (None, None, None, 32)       288       ['stem_activation[0][0]']     \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block1a_bn (BatchNormaliza  (None, None, None, 32)       128       ['block1a_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block1a_activation (Activa  (None, None, None, 32)       0         ['block1a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block1a_se_squeeze (Global  (None, 32)                   0         ['block1a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block1a_se_reshape (Reshap  (None, 1, 1, 32)             0         ['block1a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block1a_se_reduce (Conv2D)  (None, 1, 1, 8)              264       ['block1a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block1a_se_expand (Conv2D)  (None, 1, 1, 32)             288       ['block1a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block1a_se_excite (Multipl  (None, None, None, 32)       0         ['block1a_activation[0][0]',  \n",
      " y)                                                                  'block1a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block1a_project_conv (Conv  (None, None, None, 16)       512       ['block1a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block1a_project_bn (BatchN  (None, None, None, 16)       64        ['block1a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block2a_expand_conv (Conv2  (None, None, None, 96)       1536      ['block1a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block2a_expand_bn (BatchNo  (None, None, None, 96)       384       ['block2a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block2a_expand_activation   (None, None, None, 96)       0         ['block2a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block2a_dwconv_pad (ZeroPa  (None, None, None, 96)       0         ['block2a_expand_activation[0]\n",
      " dding2D)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " block2a_dwconv (DepthwiseC  (None, None, None, 96)       864       ['block2a_dwconv_pad[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block2a_bn (BatchNormaliza  (None, None, None, 96)       384       ['block2a_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block2a_activation (Activa  (None, None, None, 96)       0         ['block2a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block2a_se_squeeze (Global  (None, 96)                   0         ['block2a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block2a_se_reshape (Reshap  (None, 1, 1, 96)             0         ['block2a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block2a_se_reduce (Conv2D)  (None, 1, 1, 4)              388       ['block2a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block2a_se_expand (Conv2D)  (None, 1, 1, 96)             480       ['block2a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block2a_se_excite (Multipl  (None, None, None, 96)       0         ['block2a_activation[0][0]',  \n",
      " y)                                                                  'block2a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block2a_project_conv (Conv  (None, None, None, 24)       2304      ['block2a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block2a_project_bn (BatchN  (None, None, None, 24)       96        ['block2a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_expand_conv (Conv2  (None, None, None, 144)      3456      ['block2a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block2b_expand_bn (BatchNo  (None, None, None, 144)      576       ['block2b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block2b_expand_activation   (None, None, None, 144)      0         ['block2b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block2b_dwconv (DepthwiseC  (None, None, None, 144)      1296      ['block2b_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block2b_bn (BatchNormaliza  (None, None, None, 144)      576       ['block2b_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block2b_activation (Activa  (None, None, None, 144)      0         ['block2b_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block2b_se_squeeze (Global  (None, 144)                  0         ['block2b_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block2b_se_reshape (Reshap  (None, 1, 1, 144)            0         ['block2b_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block2b_se_reduce (Conv2D)  (None, 1, 1, 6)              870       ['block2b_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block2b_se_expand (Conv2D)  (None, 1, 1, 144)            1008      ['block2b_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block2b_se_excite (Multipl  (None, None, None, 144)      0         ['block2b_activation[0][0]',  \n",
      " y)                                                                  'block2b_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block2b_project_conv (Conv  (None, None, None, 24)       3456      ['block2b_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block2b_project_bn (BatchN  (None, None, None, 24)       96        ['block2b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_drop (Dropout)      (None, None, None, 24)       0         ['block2b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block2b_add (Add)           (None, None, None, 24)       0         ['block2b_drop[0][0]',        \n",
      "                                                                     'block2a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block3a_expand_conv (Conv2  (None, None, None, 144)      3456      ['block2b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block3a_expand_bn (BatchNo  (None, None, None, 144)      576       ['block3a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block3a_expand_activation   (None, None, None, 144)      0         ['block3a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block3a_dwconv_pad (ZeroPa  (None, None, None, 144)      0         ['block3a_expand_activation[0]\n",
      " dding2D)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " block3a_dwconv (DepthwiseC  (None, None, None, 144)      3600      ['block3a_dwconv_pad[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block3a_bn (BatchNormaliza  (None, None, None, 144)      576       ['block3a_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block3a_activation (Activa  (None, None, None, 144)      0         ['block3a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block3a_se_squeeze (Global  (None, 144)                  0         ['block3a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block3a_se_reshape (Reshap  (None, 1, 1, 144)            0         ['block3a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block3a_se_reduce (Conv2D)  (None, 1, 1, 6)              870       ['block3a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block3a_se_expand (Conv2D)  (None, 1, 1, 144)            1008      ['block3a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block3a_se_excite (Multipl  (None, None, None, 144)      0         ['block3a_activation[0][0]',  \n",
      " y)                                                                  'block3a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block3a_project_conv (Conv  (None, None, None, 40)       5760      ['block3a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block3a_project_bn (BatchN  (None, None, None, 40)       160       ['block3a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_expand_conv (Conv2  (None, None, None, 240)      9600      ['block3a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block3b_expand_bn (BatchNo  (None, None, None, 240)      960       ['block3b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block3b_expand_activation   (None, None, None, 240)      0         ['block3b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block3b_dwconv (DepthwiseC  (None, None, None, 240)      6000      ['block3b_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block3b_bn (BatchNormaliza  (None, None, None, 240)      960       ['block3b_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block3b_activation (Activa  (None, None, None, 240)      0         ['block3b_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block3b_se_squeeze (Global  (None, 240)                  0         ['block3b_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block3b_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block3b_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block3b_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block3b_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block3b_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block3b_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block3b_se_excite (Multipl  (None, None, None, 240)      0         ['block3b_activation[0][0]',  \n",
      " y)                                                                  'block3b_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block3b_project_conv (Conv  (None, None, None, 40)       9600      ['block3b_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block3b_project_bn (BatchN  (None, None, None, 40)       160       ['block3b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_drop (Dropout)      (None, None, None, 40)       0         ['block3b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block3b_add (Add)           (None, None, None, 40)       0         ['block3b_drop[0][0]',        \n",
      "                                                                     'block3a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block4a_expand_conv (Conv2  (None, None, None, 240)      9600      ['block3b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4a_expand_bn (BatchNo  (None, None, None, 240)      960       ['block4a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block4a_expand_activation   (None, None, None, 240)      0         ['block4a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block4a_dwconv_pad (ZeroPa  (None, None, None, 240)      0         ['block4a_expand_activation[0]\n",
      " dding2D)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " block4a_dwconv (DepthwiseC  (None, None, None, 240)      2160      ['block4a_dwconv_pad[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block4a_bn (BatchNormaliza  (None, None, None, 240)      960       ['block4a_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4a_activation (Activa  (None, None, None, 240)      0         ['block4a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4a_se_squeeze (Global  (None, 240)                  0         ['block4a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block4a_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block4a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block4a_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block4a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block4a_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block4a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block4a_se_excite (Multipl  (None, None, None, 240)      0         ['block4a_activation[0][0]',  \n",
      " y)                                                                  'block4a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block4a_project_conv (Conv  (None, None, None, 80)       19200     ['block4a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4a_project_bn (BatchN  (None, None, None, 80)       320       ['block4a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_expand_conv (Conv2  (None, None, None, 480)      38400     ['block4a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4b_expand_bn (BatchNo  (None, None, None, 480)      1920      ['block4b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block4b_expand_activation   (None, None, None, 480)      0         ['block4b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block4b_dwconv (DepthwiseC  (None, None, None, 480)      4320      ['block4b_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block4b_bn (BatchNormaliza  (None, None, None, 480)      1920      ['block4b_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4b_activation (Activa  (None, None, None, 480)      0         ['block4b_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4b_se_squeeze (Global  (None, 480)                  0         ['block4b_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block4b_se_reshape (Reshap  (None, 1, 1, 480)            0         ['block4b_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block4b_se_reduce (Conv2D)  (None, 1, 1, 20)             9620      ['block4b_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block4b_se_expand (Conv2D)  (None, 1, 1, 480)            10080     ['block4b_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block4b_se_excite (Multipl  (None, None, None, 480)      0         ['block4b_activation[0][0]',  \n",
      " y)                                                                  'block4b_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block4b_project_conv (Conv  (None, None, None, 80)       38400     ['block4b_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4b_project_bn (BatchN  (None, None, None, 80)       320       ['block4b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_drop (Dropout)      (None, None, None, 80)       0         ['block4b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block4b_add (Add)           (None, None, None, 80)       0         ['block4b_drop[0][0]',        \n",
      "                                                                     'block4a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block4c_expand_conv (Conv2  (None, None, None, 480)      38400     ['block4b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4c_expand_bn (BatchNo  (None, None, None, 480)      1920      ['block4c_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block4c_expand_activation   (None, None, None, 480)      0         ['block4c_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block4c_dwconv (DepthwiseC  (None, None, None, 480)      4320      ['block4c_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block4c_bn (BatchNormaliza  (None, None, None, 480)      1920      ['block4c_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4c_activation (Activa  (None, None, None, 480)      0         ['block4c_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4c_se_squeeze (Global  (None, 480)                  0         ['block4c_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block4c_se_reshape (Reshap  (None, 1, 1, 480)            0         ['block4c_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block4c_se_reduce (Conv2D)  (None, 1, 1, 20)             9620      ['block4c_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block4c_se_expand (Conv2D)  (None, 1, 1, 480)            10080     ['block4c_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block4c_se_excite (Multipl  (None, None, None, 480)      0         ['block4c_activation[0][0]',  \n",
      " y)                                                                  'block4c_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block4c_project_conv (Conv  (None, None, None, 80)       38400     ['block4c_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4c_project_bn (BatchN  (None, None, None, 80)       320       ['block4c_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block4c_drop (Dropout)      (None, None, None, 80)       0         ['block4c_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block4c_add (Add)           (None, None, None, 80)       0         ['block4c_drop[0][0]',        \n",
      "                                                                     'block4b_add[0][0]']         \n",
      "                                                                                                  \n",
      " block5a_expand_conv (Conv2  (None, None, None, 480)      38400     ['block4c_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block5a_expand_bn (BatchNo  (None, None, None, 480)      1920      ['block5a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block5a_expand_activation   (None, None, None, 480)      0         ['block5a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block5a_dwconv (DepthwiseC  (None, None, None, 480)      12000     ['block5a_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block5a_bn (BatchNormaliza  (None, None, None, 480)      1920      ['block5a_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5a_activation (Activa  (None, None, None, 480)      0         ['block5a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5a_se_squeeze (Global  (None, 480)                  0         ['block5a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block5a_se_reshape (Reshap  (None, 1, 1, 480)            0         ['block5a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block5a_se_reduce (Conv2D)  (None, 1, 1, 20)             9620      ['block5a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block5a_se_expand (Conv2D)  (None, 1, 1, 480)            10080     ['block5a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block5a_se_excite (Multipl  (None, None, None, 480)      0         ['block5a_activation[0][0]',  \n",
      " y)                                                                  'block5a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block5a_project_conv (Conv  (None, None, None, 112)      53760     ['block5a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5a_project_bn (BatchN  (None, None, None, 112)      448       ['block5a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_expand_conv (Conv2  (None, None, None, 672)      75264     ['block5a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block5b_expand_bn (BatchNo  (None, None, None, 672)      2688      ['block5b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block5b_expand_activation   (None, None, None, 672)      0         ['block5b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block5b_dwconv (DepthwiseC  (None, None, None, 672)      16800     ['block5b_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block5b_bn (BatchNormaliza  (None, None, None, 672)      2688      ['block5b_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5b_activation (Activa  (None, None, None, 672)      0         ['block5b_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5b_se_squeeze (Global  (None, 672)                  0         ['block5b_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block5b_se_reshape (Reshap  (None, 1, 1, 672)            0         ['block5b_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block5b_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     ['block5b_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block5b_se_expand (Conv2D)  (None, 1, 1, 672)            19488     ['block5b_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block5b_se_excite (Multipl  (None, None, None, 672)      0         ['block5b_activation[0][0]',  \n",
      " y)                                                                  'block5b_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block5b_project_conv (Conv  (None, None, None, 112)      75264     ['block5b_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5b_project_bn (BatchN  (None, None, None, 112)      448       ['block5b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_drop (Dropout)      (None, None, None, 112)      0         ['block5b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block5b_add (Add)           (None, None, None, 112)      0         ['block5b_drop[0][0]',        \n",
      "                                                                     'block5a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block5c_expand_conv (Conv2  (None, None, None, 672)      75264     ['block5b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block5c_expand_bn (BatchNo  (None, None, None, 672)      2688      ['block5c_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block5c_expand_activation   (None, None, None, 672)      0         ['block5c_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block5c_dwconv (DepthwiseC  (None, None, None, 672)      16800     ['block5c_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block5c_bn (BatchNormaliza  (None, None, None, 672)      2688      ['block5c_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5c_activation (Activa  (None, None, None, 672)      0         ['block5c_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5c_se_squeeze (Global  (None, 672)                  0         ['block5c_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block5c_se_reshape (Reshap  (None, 1, 1, 672)            0         ['block5c_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block5c_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     ['block5c_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block5c_se_expand (Conv2D)  (None, 1, 1, 672)            19488     ['block5c_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block5c_se_excite (Multipl  (None, None, None, 672)      0         ['block5c_activation[0][0]',  \n",
      " y)                                                                  'block5c_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block5c_project_conv (Conv  (None, None, None, 112)      75264     ['block5c_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5c_project_bn (BatchN  (None, None, None, 112)      448       ['block5c_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5c_drop (Dropout)      (None, None, None, 112)      0         ['block5c_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block5c_add (Add)           (None, None, None, 112)      0         ['block5c_drop[0][0]',        \n",
      "                                                                     'block5b_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6a_expand_conv (Conv2  (None, None, None, 672)      75264     ['block5c_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6a_expand_bn (BatchNo  (None, None, None, 672)      2688      ['block6a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6a_expand_activation   (None, None, None, 672)      0         ['block6a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6a_dwconv_pad (ZeroPa  (None, None, None, 672)      0         ['block6a_expand_activation[0]\n",
      " dding2D)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " block6a_dwconv (DepthwiseC  (None, None, None, 672)      16800     ['block6a_dwconv_pad[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block6a_bn (BatchNormaliza  (None, None, None, 672)      2688      ['block6a_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6a_activation (Activa  (None, None, None, 672)      0         ['block6a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6a_se_squeeze (Global  (None, 672)                  0         ['block6a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6a_se_reshape (Reshap  (None, 1, 1, 672)            0         ['block6a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6a_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     ['block6a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6a_se_expand (Conv2D)  (None, 1, 1, 672)            19488     ['block6a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6a_se_excite (Multipl  (None, None, None, 672)      0         ['block6a_activation[0][0]',  \n",
      " y)                                                                  'block6a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6a_project_conv (Conv  (None, None, None, 192)      129024    ['block6a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6a_project_bn (BatchN  (None, None, None, 192)      768       ['block6a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_expand_conv (Conv2  (None, None, None, 1152)     221184    ['block6a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6b_expand_bn (BatchNo  (None, None, None, 1152)     4608      ['block6b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6b_expand_activation   (None, None, None, 1152)     0         ['block6b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6b_dwconv (DepthwiseC  (None, None, None, 1152)     28800     ['block6b_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block6b_bn (BatchNormaliza  (None, None, None, 1152)     4608      ['block6b_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6b_activation (Activa  (None, None, None, 1152)     0         ['block6b_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6b_se_squeeze (Global  (None, 1152)                 0         ['block6b_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6b_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6b_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6b_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6b_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6b_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6b_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6b_se_excite (Multipl  (None, None, None, 1152)     0         ['block6b_activation[0][0]',  \n",
      " y)                                                                  'block6b_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6b_project_conv (Conv  (None, None, None, 192)      221184    ['block6b_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6b_project_bn (BatchN  (None, None, None, 192)      768       ['block6b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_drop (Dropout)      (None, None, None, 192)      0         ['block6b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6b_add (Add)           (None, None, None, 192)      0         ['block6b_drop[0][0]',        \n",
      "                                                                     'block6a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6c_expand_conv (Conv2  (None, None, None, 1152)     221184    ['block6b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6c_expand_bn (BatchNo  (None, None, None, 1152)     4608      ['block6c_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6c_expand_activation   (None, None, None, 1152)     0         ['block6c_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6c_dwconv (DepthwiseC  (None, None, None, 1152)     28800     ['block6c_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block6c_bn (BatchNormaliza  (None, None, None, 1152)     4608      ['block6c_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6c_activation (Activa  (None, None, None, 1152)     0         ['block6c_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6c_se_squeeze (Global  (None, 1152)                 0         ['block6c_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6c_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6c_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6c_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6c_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6c_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6c_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6c_se_excite (Multipl  (None, None, None, 1152)     0         ['block6c_activation[0][0]',  \n",
      " y)                                                                  'block6c_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6c_project_conv (Conv  (None, None, None, 192)      221184    ['block6c_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6c_project_bn (BatchN  (None, None, None, 192)      768       ['block6c_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6c_drop (Dropout)      (None, None, None, 192)      0         ['block6c_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6c_add (Add)           (None, None, None, 192)      0         ['block6c_drop[0][0]',        \n",
      "                                                                     'block6b_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6d_expand_conv (Conv2  (None, None, None, 1152)     221184    ['block6c_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6d_expand_bn (BatchNo  (None, None, None, 1152)     4608      ['block6d_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6d_expand_activation   (None, None, None, 1152)     0         ['block6d_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6d_dwconv (DepthwiseC  (None, None, None, 1152)     28800     ['block6d_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block6d_bn (BatchNormaliza  (None, None, None, 1152)     4608      ['block6d_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6d_activation (Activa  (None, None, None, 1152)     0         ['block6d_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6d_se_squeeze (Global  (None, 1152)                 0         ['block6d_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6d_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6d_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6d_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6d_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6d_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6d_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6d_se_excite (Multipl  (None, None, None, 1152)     0         ['block6d_activation[0][0]',  \n",
      " y)                                                                  'block6d_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6d_project_conv (Conv  (None, None, None, 192)      221184    ['block6d_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6d_project_bn (BatchN  (None, None, None, 192)      768       ['block6d_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6d_drop (Dropout)      (None, None, None, 192)      0         ['block6d_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6d_add (Add)           (None, None, None, 192)      0         ['block6d_drop[0][0]',        \n",
      "                                                                     'block6c_add[0][0]']         \n",
      "                                                                                                  \n",
      " block7a_expand_conv (Conv2  (None, None, None, 1152)     221184    ['block6d_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block7a_expand_bn (BatchNo  (None, None, None, 1152)     4608      ['block7a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block7a_expand_activation   (None, None, None, 1152)     0         ['block7a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block7a_dwconv (DepthwiseC  (None, None, None, 1152)     10368     ['block7a_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block7a_bn (BatchNormaliza  (None, None, None, 1152)     4608      ['block7a_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block7a_activation (Activa  (None, None, None, 1152)     0         ['block7a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block7a_se_squeeze (Global  (None, 1152)                 0         ['block7a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block7a_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block7a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block7a_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block7a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block7a_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block7a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block7a_se_excite (Multipl  (None, None, None, 1152)     0         ['block7a_activation[0][0]',  \n",
      " y)                                                                  'block7a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block7a_project_conv (Conv  (None, None, None, 320)      368640    ['block7a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block7a_project_bn (BatchN  (None, None, None, 320)      1280      ['block7a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " top_conv (Conv2D)           (None, None, None, 1280)     409600    ['block7a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " top_bn (BatchNormalization  (None, None, None, 1280)     5120      ['top_conv[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " top_activation (Activation  (None, None, None, 1280)     0         ['top_bn[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4049571 (15.45 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 4049571 (15.45 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()\n",
    "#here, rescaling is done by the model so we shouldn't rescale the dataset for this model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)        [(None, None, None, 3)]      0         []                            \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)   (None, None, None, 3)        0         ['input_8[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)         (None, None, None, 64)       9472      ['conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalizati  (None, None, None, 64)       256       ['conv1_conv[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)     (None, None, None, 64)       0         ['conv1_bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)   (None, None, None, 64)       0         ['conv1_relu[0][0]']          \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)   (None, None, None, 64)       0         ['pool1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, None, None, 64)       4160      ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, None, None, 64)       0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, None, None, 64)       36928     ['conv2_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activ  (None, None, None, 64)       0         ['conv2_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2  (None, None, None, 256)      16640     ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2  (None, None, None, 256)      16640     ['conv2_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)      (None, None, None, 256)      0         ['conv2_block1_0_bn[0][0]',   \n",
      "                                                                     'conv2_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activati  (None, None, None, 256)      0         ['conv2_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, None, None, 64)       16448     ['conv2_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, None, None, 64)       0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, None, None, 64)       36928     ['conv2_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activ  (None, None, None, 64)       0         ['conv2_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2  (None, None, None, 256)      16640     ['conv2_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)      (None, None, None, 256)      0         ['conv2_block1_out[0][0]',    \n",
      "                                                                     'conv2_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activati  (None, None, None, 256)      0         ['conv2_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, None, None, 64)       16448     ['conv2_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, None, None, 64)       0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, None, None, 64)       36928     ['conv2_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNo  (None, None, None, 64)       256       ['conv2_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activ  (None, None, None, 64)       0         ['conv2_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2  (None, None, None, 256)      16640     ['conv2_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNo  (None, None, None, 256)      1024      ['conv2_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)      (None, None, None, 256)      0         ['conv2_block2_out[0][0]',    \n",
      "                                                                     'conv2_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activati  (None, None, None, 256)      0         ['conv2_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, None, None, 128)      32896     ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2  (None, None, None, 512)      131584    ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)      (None, None, None, 512)      0         ['conv3_block1_0_bn[0][0]',   \n",
      "                                                                     'conv3_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activati  (None, None, None, 512)      0         ['conv3_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, None, None, 128)      65664     ['conv3_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)      (None, None, None, 512)      0         ['conv3_block1_out[0][0]',    \n",
      "                                                                     'conv3_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activati  (None, None, None, 512)      0         ['conv3_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, None, None, 128)      65664     ['conv3_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)      (None, None, None, 512)      0         ['conv3_block2_out[0][0]',    \n",
      "                                                                     'conv3_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activati  (None, None, None, 512)      0         ['conv3_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, None, None, 128)      65664     ['conv3_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, None, None, 128)      0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, None, None, 128)      147584    ['conv3_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNo  (None, None, None, 128)      512       ['conv3_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activ  (None, None, None, 128)      0         ['conv3_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2  (None, None, None, 512)      66048     ['conv3_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNo  (None, None, None, 512)      2048      ['conv3_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)      (None, None, None, 512)      0         ['conv3_block3_out[0][0]',    \n",
      "                                                                     'conv3_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activati  (None, None, None, 512)      0         ['conv3_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, None, None, 256)      131328    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2  (None, None, None, 1024)     525312    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)      (None, None, None, 1024)     0         ['conv4_block1_0_bn[0][0]',   \n",
      "                                                                     'conv4_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activati  (None, None, None, 1024)     0         ['conv4_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)      (None, None, None, 1024)     0         ['conv4_block1_out[0][0]',    \n",
      "                                                                     'conv4_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activati  (None, None, None, 1024)     0         ['conv4_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)      (None, None, None, 1024)     0         ['conv4_block2_out[0][0]',    \n",
      "                                                                     'conv4_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activati  (None, None, None, 1024)     0         ['conv4_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)      (None, None, None, 1024)     0         ['conv4_block3_out[0][0]',    \n",
      "                                                                     'conv4_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activati  (None, None, None, 1024)     0         ['conv4_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block5_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block5_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block5_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block5_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block5_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)      (None, None, None, 1024)     0         ['conv4_block4_out[0][0]',    \n",
      "                                                                     'conv4_block5_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activati  (None, None, None, 1024)     0         ['conv4_block5_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2  (None, None, None, 256)      262400    ['conv4_block5_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activ  (None, None, None, 256)      0         ['conv4_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2  (None, None, None, 256)      590080    ['conv4_block6_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNo  (None, None, None, 256)      1024      ['conv4_block6_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activ  (None, None, None, 256)      0         ['conv4_block6_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2  (None, None, None, 1024)     263168    ['conv4_block6_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNo  (None, None, None, 1024)     4096      ['conv4_block6_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)      (None, None, None, 1024)     0         ['conv4_block5_out[0][0]',    \n",
      "                                                                     'conv4_block6_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activati  (None, None, None, 1024)     0         ['conv4_block6_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2  (None, None, None, 512)      524800    ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activ  (None, None, None, 512)      0         ['conv5_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2  (None, None, None, 512)      2359808   ['conv5_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activ  (None, None, None, 512)      0         ['conv5_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2  (None, None, None, 2048)     2099200   ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2  (None, None, None, 2048)     1050624   ['conv5_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)      (None, None, None, 2048)     0         ['conv5_block1_0_bn[0][0]',   \n",
      "                                                                     'conv5_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activati  (None, None, None, 2048)     0         ['conv5_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2  (None, None, None, 512)      1049088   ['conv5_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activ  (None, None, None, 512)      0         ['conv5_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2  (None, None, None, 512)      2359808   ['conv5_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activ  (None, None, None, 512)      0         ['conv5_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2  (None, None, None, 2048)     1050624   ['conv5_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)      (None, None, None, 2048)     0         ['conv5_block1_out[0][0]',    \n",
      "                                                                     'conv5_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activati  (None, None, None, 2048)     0         ['conv5_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2  (None, None, None, 512)      1049088   ['conv5_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activ  (None, None, None, 512)      0         ['conv5_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2  (None, None, None, 512)      2359808   ['conv5_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNo  (None, None, None, 512)      2048      ['conv5_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activ  (None, None, None, 512)      0         ['conv5_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2  (None, None, None, 2048)     1050624   ['conv5_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNo  (None, None, None, 2048)     8192      ['conv5_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)      (None, None, None, 2048)     0         ['conv5_block2_out[0][0]',    \n",
      "                                                                     'conv5_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activati  (None, None, None, 2048)     0         ['conv5_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23587712 (89.98 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model_2 = tf.keras.applications.ResNet50(include_top = False) #another pre-trained model\n",
    "base_model_2.trainable = False\n",
    "base_model_2.summary()\n",
    "#here, model doesn't rescale by itself => we need to rescale the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7500 images belonging to 10 classes.\n",
      "Found 2500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255) #no rescaling required as pre-trained model is already rescaling it\n",
    "test_datagen = ImageDataGenerator(rescale = 1/255.)  #if we rescale again, we'll get bad accuracy\n",
    "\n",
    "\n",
    "train_data = train_datagen.flow_from_directory('10_food_classes_all_data/train/',\n",
    "                                   batch_size = 32,\n",
    "                                  target_size=(128, 128),\n",
    "                                   class_mode='categorical',\n",
    "                                   shuffle = True, #shuffle is required because data is highly ordered into respective classes\n",
    "                                   seed=42)\n",
    "test_data = test_datagen.flow_from_directory('10_food_classes_all_data/test/',\n",
    "                                  batch_size=32,\n",
    "                                  target_size=(128, 128),\n",
    "                                  class_mode='categorical',\n",
    "                                  shuffle = True,\n",
    "                                  seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape = (128, 128, 3))\n",
    "x = base_model(inputs) #directly pass it through base model\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "#x = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation = 'softmax')(x)\n",
    "model = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    "              metrics = ['accuracy'] \n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb0 (Functional  (None, None, None, 1280   4049571   \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " global_average_pooling2d_3  (None, 1280)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                12810     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4062381 (15.50 MB)\n",
      "Trainable params: 12810 (50.04 KB)\n",
      "Non-trainable params: 4049571 (15.45 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/235 [==============================] - 35s 136ms/step - loss: 2.3318 - accuracy: 0.1016 - val_loss: 2.3092 - val_accuracy: 0.1292\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 34s 143ms/step - loss: 2.3323 - accuracy: 0.0973 - val_loss: 2.3296 - val_accuracy: 0.0896\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 34s 143ms/step - loss: 2.3297 - accuracy: 0.0912 - val_loss: 2.3348 - val_accuracy: 0.0833\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 34s 145ms/step - loss: 2.3291 - accuracy: 0.1000 - val_loss: 2.3179 - val_accuracy: 0.1000\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 35s 146ms/step - loss: 2.3270 - accuracy: 0.1004 - val_loss: 2.3222 - val_accuracy: 0.0896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2cbc2ae50>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, epochs = 5,\n",
    "           validation_data = test_data,\n",
    "           steps_per_epoch = len(train_data), #no. of steps taken on validation curve\n",
    "           validation_steps = int(0.2 * len(test_data))) \n",
    "#only 20% of test data is chosen to learn => slowly and accurately learns it\n",
    "\n",
    "#very bad accuracy, as the number of neurons in ResNet is lesser than that of EfficientNetB0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_model.layers) #number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_model_2.layers) #number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True #every layer in base_model cannot be changeable\n",
    "# => to make last 10 layers as changeable => need to unfreeze them with trainable = True \n",
    "for i, layer in enumerate(base_model.layers[:-10]):\n",
    "    layer.trainable = False #last 10 layers are trainable(freezed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_5 False\n",
      "1 rescaling_2 False\n",
      "2 normalization_1 False\n",
      "3 rescaling_3 False\n",
      "4 stem_conv_pad False\n",
      "5 stem_conv False\n",
      "6 stem_bn False\n",
      "7 stem_activation False\n",
      "8 block1a_dwconv False\n",
      "9 block1a_bn False\n",
      "10 block1a_activation False\n",
      "11 block1a_se_squeeze False\n",
      "12 block1a_se_reshape False\n",
      "13 block1a_se_reduce False\n",
      "14 block1a_se_expand False\n",
      "15 block1a_se_excite False\n",
      "16 block1a_project_conv False\n",
      "17 block1a_project_bn False\n",
      "18 block2a_expand_conv False\n",
      "19 block2a_expand_bn False\n",
      "20 block2a_expand_activation False\n",
      "21 block2a_dwconv_pad False\n",
      "22 block2a_dwconv False\n",
      "23 block2a_bn False\n",
      "24 block2a_activation False\n",
      "25 block2a_se_squeeze False\n",
      "26 block2a_se_reshape False\n",
      "27 block2a_se_reduce False\n",
      "28 block2a_se_expand False\n",
      "29 block2a_se_excite False\n",
      "30 block2a_project_conv False\n",
      "31 block2a_project_bn False\n",
      "32 block2b_expand_conv False\n",
      "33 block2b_expand_bn False\n",
      "34 block2b_expand_activation False\n",
      "35 block2b_dwconv False\n",
      "36 block2b_bn False\n",
      "37 block2b_activation False\n",
      "38 block2b_se_squeeze False\n",
      "39 block2b_se_reshape False\n",
      "40 block2b_se_reduce False\n",
      "41 block2b_se_expand False\n",
      "42 block2b_se_excite False\n",
      "43 block2b_project_conv False\n",
      "44 block2b_project_bn False\n",
      "45 block2b_drop False\n",
      "46 block2b_add False\n",
      "47 block3a_expand_conv False\n",
      "48 block3a_expand_bn False\n",
      "49 block3a_expand_activation False\n",
      "50 block3a_dwconv_pad False\n",
      "51 block3a_dwconv False\n",
      "52 block3a_bn False\n",
      "53 block3a_activation False\n",
      "54 block3a_se_squeeze False\n",
      "55 block3a_se_reshape False\n",
      "56 block3a_se_reduce False\n",
      "57 block3a_se_expand False\n",
      "58 block3a_se_excite False\n",
      "59 block3a_project_conv False\n",
      "60 block3a_project_bn False\n",
      "61 block3b_expand_conv False\n",
      "62 block3b_expand_bn False\n",
      "63 block3b_expand_activation False\n",
      "64 block3b_dwconv False\n",
      "65 block3b_bn False\n",
      "66 block3b_activation False\n",
      "67 block3b_se_squeeze False\n",
      "68 block3b_se_reshape False\n",
      "69 block3b_se_reduce False\n",
      "70 block3b_se_expand False\n",
      "71 block3b_se_excite False\n",
      "72 block3b_project_conv False\n",
      "73 block3b_project_bn False\n",
      "74 block3b_drop False\n",
      "75 block3b_add False\n",
      "76 block4a_expand_conv False\n",
      "77 block4a_expand_bn False\n",
      "78 block4a_expand_activation False\n",
      "79 block4a_dwconv_pad False\n",
      "80 block4a_dwconv False\n",
      "81 block4a_bn False\n",
      "82 block4a_activation False\n",
      "83 block4a_se_squeeze False\n",
      "84 block4a_se_reshape False\n",
      "85 block4a_se_reduce False\n",
      "86 block4a_se_expand False\n",
      "87 block4a_se_excite False\n",
      "88 block4a_project_conv False\n",
      "89 block4a_project_bn False\n",
      "90 block4b_expand_conv False\n",
      "91 block4b_expand_bn False\n",
      "92 block4b_expand_activation False\n",
      "93 block4b_dwconv False\n",
      "94 block4b_bn False\n",
      "95 block4b_activation False\n",
      "96 block4b_se_squeeze False\n",
      "97 block4b_se_reshape False\n",
      "98 block4b_se_reduce False\n",
      "99 block4b_se_expand False\n",
      "100 block4b_se_excite False\n",
      "101 block4b_project_conv False\n",
      "102 block4b_project_bn False\n",
      "103 block4b_drop False\n",
      "104 block4b_add False\n",
      "105 block4c_expand_conv False\n",
      "106 block4c_expand_bn False\n",
      "107 block4c_expand_activation False\n",
      "108 block4c_dwconv False\n",
      "109 block4c_bn False\n",
      "110 block4c_activation False\n",
      "111 block4c_se_squeeze False\n",
      "112 block4c_se_reshape False\n",
      "113 block4c_se_reduce False\n",
      "114 block4c_se_expand False\n",
      "115 block4c_se_excite False\n",
      "116 block4c_project_conv False\n",
      "117 block4c_project_bn False\n",
      "118 block4c_drop False\n",
      "119 block4c_add False\n",
      "120 block5a_expand_conv False\n",
      "121 block5a_expand_bn False\n",
      "122 block5a_expand_activation False\n",
      "123 block5a_dwconv False\n",
      "124 block5a_bn False\n",
      "125 block5a_activation False\n",
      "126 block5a_se_squeeze False\n",
      "127 block5a_se_reshape False\n",
      "128 block5a_se_reduce False\n",
      "129 block5a_se_expand False\n",
      "130 block5a_se_excite False\n",
      "131 block5a_project_conv False\n",
      "132 block5a_project_bn False\n",
      "133 block5b_expand_conv False\n",
      "134 block5b_expand_bn False\n",
      "135 block5b_expand_activation False\n",
      "136 block5b_dwconv False\n",
      "137 block5b_bn False\n",
      "138 block5b_activation False\n",
      "139 block5b_se_squeeze False\n",
      "140 block5b_se_reshape False\n",
      "141 block5b_se_reduce False\n",
      "142 block5b_se_expand False\n",
      "143 block5b_se_excite False\n",
      "144 block5b_project_conv False\n",
      "145 block5b_project_bn False\n",
      "146 block5b_drop False\n",
      "147 block5b_add False\n",
      "148 block5c_expand_conv False\n",
      "149 block5c_expand_bn False\n",
      "150 block5c_expand_activation False\n",
      "151 block5c_dwconv False\n",
      "152 block5c_bn False\n",
      "153 block5c_activation False\n",
      "154 block5c_se_squeeze False\n",
      "155 block5c_se_reshape False\n",
      "156 block5c_se_reduce False\n",
      "157 block5c_se_expand False\n",
      "158 block5c_se_excite False\n",
      "159 block5c_project_conv False\n",
      "160 block5c_project_bn False\n",
      "161 block5c_drop False\n",
      "162 block5c_add False\n",
      "163 block6a_expand_conv False\n",
      "164 block6a_expand_bn False\n",
      "165 block6a_expand_activation False\n",
      "166 block6a_dwconv_pad False\n",
      "167 block6a_dwconv False\n",
      "168 block6a_bn False\n",
      "169 block6a_activation False\n",
      "170 block6a_se_squeeze False\n",
      "171 block6a_se_reshape False\n",
      "172 block6a_se_reduce False\n",
      "173 block6a_se_expand False\n",
      "174 block6a_se_excite False\n",
      "175 block6a_project_conv False\n",
      "176 block6a_project_bn False\n",
      "177 block6b_expand_conv False\n",
      "178 block6b_expand_bn False\n",
      "179 block6b_expand_activation False\n",
      "180 block6b_dwconv False\n",
      "181 block6b_bn False\n",
      "182 block6b_activation False\n",
      "183 block6b_se_squeeze False\n",
      "184 block6b_se_reshape False\n",
      "185 block6b_se_reduce False\n",
      "186 block6b_se_expand False\n",
      "187 block6b_se_excite False\n",
      "188 block6b_project_conv False\n",
      "189 block6b_project_bn False\n",
      "190 block6b_drop False\n",
      "191 block6b_add False\n",
      "192 block6c_expand_conv False\n",
      "193 block6c_expand_bn False\n",
      "194 block6c_expand_activation False\n",
      "195 block6c_dwconv False\n",
      "196 block6c_bn False\n",
      "197 block6c_activation False\n",
      "198 block6c_se_squeeze False\n",
      "199 block6c_se_reshape False\n",
      "200 block6c_se_reduce False\n",
      "201 block6c_se_expand False\n",
      "202 block6c_se_excite False\n",
      "203 block6c_project_conv False\n",
      "204 block6c_project_bn False\n",
      "205 block6c_drop False\n",
      "206 block6c_add False\n",
      "207 block6d_expand_conv False\n",
      "208 block6d_expand_bn False\n",
      "209 block6d_expand_activation False\n",
      "210 block6d_dwconv False\n",
      "211 block6d_bn False\n",
      "212 block6d_activation False\n",
      "213 block6d_se_squeeze False\n",
      "214 block6d_se_reshape False\n",
      "215 block6d_se_reduce False\n",
      "216 block6d_se_expand False\n",
      "217 block6d_se_excite False\n",
      "218 block6d_project_conv False\n",
      "219 block6d_project_bn False\n",
      "220 block6d_drop False\n",
      "221 block6d_add False\n",
      "222 block7a_expand_conv False\n",
      "223 block7a_expand_bn False\n",
      "224 block7a_expand_activation False\n",
      "225 block7a_dwconv False\n",
      "226 block7a_bn False\n",
      "227 block7a_activation False\n",
      "228 block7a_se_squeeze True\n",
      "229 block7a_se_reshape True\n",
      "230 block7a_se_reduce True\n",
      "231 block7a_se_expand True\n",
      "232 block7a_se_excite True\n",
      "233 block7a_project_conv True\n",
      "234 block7a_project_bn True\n",
      "235 top_conv True\n",
      "236 top_bn True\n",
      "237 top_activation True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb0 (Functional  (None, None, None, 1280   4049571   \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " global_average_pooling2d_2  (None, 1280)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                12810     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4062381 (15.50 MB)\n",
      "Trainable params: 906042 (3.46 MB)\n",
      "Non-trainable params: 3156339 (12.04 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#now last 10 layers of base model can have their weights changed\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "117/235 [=============>................] - ETA: 15s - loss: 2.3035 - accuracy: 0.1155"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mCategoricalCrossentropy(),\n\u001b[1;32m      2\u001b[0m               optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mlegacy\u001b[38;5;241m.\u001b[39mAdam(learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m), \n\u001b[1;32m      3\u001b[0m               \u001b[38;5;66;03m#new lr = old lr / 10 because due to 10 freezed layers, model has become sensitive so we compensate for it\u001b[39;00m\n\u001b[1;32m      4\u001b[0m               metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[1;32m      5\u001b[0m               )\n\u001b[0;32m----> 7\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_data, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      8\u001b[0m            validation_data \u001b[38;5;241m=\u001b[39m test_data,\n\u001b[1;32m      9\u001b[0m            steps_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_data), \u001b[38;5;66;03m#no. of steps taken on validation curve\u001b[39;00m\n\u001b[1;32m     10\u001b[0m            validation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_data)),\n\u001b[1;32m     11\u001b[0m             initial_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    869\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[1;32m    870\u001b[0m   )\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1487\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1488\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1489\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1490\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1491\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1492\u001b[0m   )\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer = tf.keras.optimizers.legacy.Adam(learning_rate = 0.0001), \n",
    "              #new lr = old lr / 10 because due to 10 freezed layers, model has become sensitive so we compensate for it\n",
    "              metrics = ['accuracy'] \n",
    "              )\n",
    "\n",
    "model.fit(train_data, epochs = 10,\n",
    "           validation_data = test_data,\n",
    "           steps_per_epoch = len(train_data), #no. of steps taken on validation curve\n",
    "           validation_steps = int(0.2 * len(test_data)),\n",
    "            initial_epoch = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Steps in any Transfer Learning working:\n",
    "1) Import the model\n",
    "2) set trainable = False\n",
    "3) Fit the model\n",
    "4) Unfreeze last few rows\n",
    "5) lr' = lr / 10 (lr - learning rate)\n",
    "6) Fit the model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile \n",
    "zip = zipfile.ZipFile(\"101_food_classes_10_percent.zip\")\n",
    "zip.extractall()\n",
    "zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7575 images belonging to 101 classes.\n",
      "Found 25250 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.,\n",
    "                                   rotation_range=0.6,\n",
    "                                   shear_range = 0.7,\n",
    "                                   zoom_range=0.5,\n",
    "                                   horizontal_flip = True) #basic data augmentation\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.,\n",
    "                                   rotation_range=0.6,\n",
    "                                   shear_range = 0.7,\n",
    "                                   zoom_range=0.5,\n",
    "                                   horizontal_flip = True) #basic data augmentation\n",
    "\n",
    "train_data = train_datagen.flow_from_directory('101_food_classes_10_percent/train',\n",
    "                                               class_mode = 'categorical',\n",
    "                                               batch_size = 32,\n",
    "                                               shuffle = True,\n",
    "                                               target_size = (128,128))\n",
    "\n",
    "test_data = test_datagen.flow_from_directory('101_food_classes_10_percent/test',\n",
    "                                               class_mode = 'categorical',\n",
    "                                               batch_size = 32,\n",
    "                                               shuffle = True,\n",
    "                                               target_size = (128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "237/237 [==============================] - 73s 298ms/step - loss: 4.7222 - accuracy: 0.0075 - val_loss: 4.7193 - val_accuracy: 0.0087\n",
      "Epoch 2/5\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 4.7106 - accuracy: 0.0087 - val_loss: 4.6875 - val_accuracy: 0.0097\n",
      "Epoch 3/5\n",
      "237/237 [==============================] - 69s 291ms/step - loss: 4.7141 - accuracy: 0.0104 - val_loss: 4.7006 - val_accuracy: 0.0093\n",
      "Epoch 4/5\n",
      "237/237 [==============================] - 67s 281ms/step - loss: 4.7142 - accuracy: 0.0088 - val_loss: 4.6903 - val_accuracy: 0.0093\n",
      "Epoch 5/5\n",
      "237/237 [==============================] - 66s 279ms/step - loss: 4.7155 - accuracy: 0.0096 - val_loss: 4.6934 - val_accuracy: 0.0113\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB0(include_top = False) #pre-trained model with hundreds of layers\n",
    "#include_top = False doesn't import the input layer of the model as we are giving our model to it\n",
    "base_model.trainable = False #we are not training base model with our inputs !!!\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape = (128, 128, 3))\n",
    "x = base_model(inputs) #directly pass it through base model\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(101, activation = 'softmax')(x)\n",
    "model = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer = tf.keras.optimizers.legacy.Adam(),\n",
    "              metrics = ['accuracy'] \n",
    "              )\n",
    "\n",
    "hist = model.fit(train_data,\n",
    "                 epochs = 5,\n",
    "                 validation_data = test_data,\n",
    "                 validation_steps = int(0.2 * len(test_data)))\n",
    "\n",
    "#very very poor val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
